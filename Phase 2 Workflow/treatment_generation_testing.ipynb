{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff244022",
   "metadata": {},
   "source": [
    "# Treatment Generation Script - Notebook Version\n",
    "\n",
    "This notebook converts the `treatment_generation.py` script into modular, testable code blocks. Each utility function and main workflow step is separated for clarity and easier debugging.\n",
    "\n",
    "You can run and test each section independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f82c91",
   "metadata": {},
   "source": [
    "## 1. Imports and Environment Setup\n",
    "\n",
    "This section sets up the environment and imports all required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "991a1cd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../libs\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\u001b[34;43m__file__\u001b[39;49m), \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmongodb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_all_file_ids, _get_mongo_client, get_document_by_fileid, _clean_raw_llm_response\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibs\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgemini_processor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiProcessor\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# Add parent and libs directory to sys.path for imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "sys.path.append('../libs')\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
    "\n",
    "from libs.mongodb import get_all_file_ids, _get_mongo_client, get_document_by_fileid, _clean_raw_llm_response\n",
    "from libs.gemini_processor import GeminiProcessor\n",
    "from utils import get_logger\n",
    "import json\n",
    "import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9997ebb6",
   "metadata": {},
   "source": [
    "## 2. Configuration and Constants\n",
    "\n",
    "Set up sector, MongoDB, Gemini model, and file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd198305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Sector we are processing\n",
    "SECTOR = \"ITC\"\n",
    "\n",
    "# MongoDB configuration\n",
    "MONGO_CLIENT = _get_mongo_client()\n",
    "DB_NAME = \"Resume_study\"\n",
    "SOURCE_COLLECTION_NAME = \"Standardized_resume_data\"\n",
    "TARGET_COLLECTION_NAME = \"Treated_resumes\"\n",
    "\n",
    "# Gemini model configuration\n",
    "GEMINI_MODEL_NAME = \"gemini-2.5-flash\"\n",
    "GEMINI_TEMPERATURE = 0.7\n",
    "ENABLE_GOOGLE_SEARCH = False\n",
    "PROMPT_TEMPLATE_PATH = \"Phase 2 Workflow/Prompts/prompt_treatment_generation.md\"\n",
    "MAX_RETRIES = 2\n",
    "STYLE_MODIFIERS = [\n",
    "    \"using strong, action-oriented verbs and focusing on quantifiable outcomes\",\n",
    "    \"using a direct, concise, and professional tone, prioritizing clarity and brevity\",\n",
    "    \"by emphasizing collaborative efforts and cross-functional teamwork\",\n",
    "    \"by highlighting strategic thinking and the business impact of the work\",\n",
    "    \"by describing the technical aspects of the work with more precision and detail\",\n",
    "    \"by framing the accomplishments as a narrative of challenges, actions, and results\"\n",
    "]\n",
    "\n",
    "# Treatment file paths\n",
    "TREATMENT_CEC_FILE = \"Phase 2 Workflow/Education_treatment_dummy.xlsx\"\n",
    "TREATMENT_CWE_FILE = \"Phase 2 Workflow/WE_treatment_dummy.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b377a2",
   "metadata": {},
   "source": [
    "## 3. Load Treatment Data and Similarity Model\n",
    "\n",
    "This section loads the treatment data from Excel files and initializes the sentence transformer model for cosine similarity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load treatment data from Excel files in pandas DataFrames\n",
    "cec_treatment_df = pd.read_excel(TREATMENT_CEC_FILE)\n",
    "cec_treatment_df = cec_treatment_df[cec_treatment_df['sector'] == SECTOR].reset_index(drop=True)\n",
    "cwe_treatment_df = pd.read_excel(TREATMENT_CWE_FILE)\n",
    "cwe_treatment_df = cwe_treatment_df[cwe_treatment_df['sector'] == SECTOR].reset_index(drop=True)\n",
    "\n",
    "# Load the model once to be reused in the loop for cosine similarity calculations\n",
    "SIMILARITY_MODEL = SentenceTransformer(\n",
    "    r'Phase 2 Workflow/models/all-MiniLM-L6-v2'\n",
    " )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c06376",
   "metadata": {},
   "source": [
    "## 4. Utility Functions\n",
    "\n",
    "The following cells define utility functions used throughout the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_focused_similarity(control_resume_data, treated_resume_data):\n",
    "    control_text = extract_rephrased_text(control_resume_data)\n",
    "    treated_text = extract_rephrased_text(treated_resume_data)\n",
    "    \n",
    "    if not control_text or not treated_text:\n",
    "        return 0.0\n",
    "\n",
    "    control_embedding = SIMILARITY_MODEL.encode(control_text)\n",
    "    treated_embedding = SIMILARITY_MODEL.encode(treated_text)\n",
    "    \n",
    "    score = cosine_similarity([control_embedding], [treated_embedding])[0][0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_and_prepare_treatments(\n",
    "    cec_treatment_df: pd.DataFrame,\n",
    "    cwe_treatment_df: pd.DataFrame,\n",
    "    source_resume_data: dict,\n",
    "    treatment_prompt_template: str,\n",
    "    style_modifiers: list[str]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Selects random treatments, assigns unique style modifiers, and prepares prompts\n",
    "    for the 3 treated resume variations (Type I, Type II, Type III).\n",
    "\n",
    "    The 'Control' version is the original source resume and is handled separately.\n",
    "    \"\"\"\n",
    "    if cec_treatment_df.empty or cwe_treatment_df.empty:\n",
    "        logger.error(\"No treatments available for CEC or CWE.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        cec_treatments = cec_treatment_df.sample(n=2, replace=False).to_dict('records')\n",
    "        cwe_treatments = cwe_treatment_df.sample(n=2, replace=False).to_dict('records')\n",
    "    except ValueError:\n",
    "        logger.error(\"Not enough unique treatments available in the dataframes to sample.\")\n",
    "        return None\n",
    "\n",
    "    if len(style_modifiers) < 3:\n",
    "        logger.error(\"Not enough style modifiers to ensure unique styles for all treatments.\")\n",
    "        return None\n",
    "    shuffled_styles = random.sample(style_modifiers, 3)\n",
    "\n",
    "    treatment_prompts = {}\n",
    "    base_prompt = treatment_prompt_template.replace(\n",
    "        \"{JSON_resume_object}\", json.dumps(source_resume_data, indent=2)\n",
    "    )\n",
    "\n",
    "    # Type I (CEC)\n",
    "    cec_treatment_idx = random.randint(0, 1)\n",
    "    cec_treatment = cec_treatments[cec_treatment_idx]\n",
    "    type_i_prompt = base_prompt.replace(\"{Treatment_object}\", str(cec_treatment))\n",
    "    type_i_style_guide = shuffled_styles.pop()\n",
    "    type_i_prompt = type_i_prompt.replace(\"{style_guide}\", type_i_style_guide)\n",
    "    treatment_prompts[\"Type_I\"] = {\n",
    "        \"prompt\": type_i_prompt,\n",
    "        \"style_guide\": type_i_style_guide,\n",
    "        \"treatment_applied\": {\"Canadian_Education\": cec_treatment}\n",
    "    }\n",
    "    cec_treatment_idx = 1 - cec_treatment_idx\n",
    "\n",
    "    # Type II (CWE)\n",
    "    cwe_treatment_idx = random.randint(0, 1)\n",
    "    cwe_treatment = cwe_treatments[cwe_treatment_idx]\n",
    "    type_ii_prompt = base_prompt.replace(\"{Treatment_object}\", str(cwe_treatment))\n",
    "    type_ii_style_guide = shuffled_styles.pop()\n",
    "    type_ii_prompt = type_ii_prompt.replace(\"{style_guide}\", type_ii_style_guide)\n",
    "    treatment_prompts[\"Type_II\"] = {\n",
    "        \"prompt\": type_ii_prompt,\n",
    "        \"style_guide\": type_ii_style_guide,\n",
    "        \"treatment_applied\": {\"Canadian_Work_Experience\": cwe_treatment}\n",
    "    }\n",
    "    cwe_treatment_idx = 1 - cwe_treatment_idx\n",
    "\n",
    "    # Type III (CEC + CWE)\n",
    "    mixed_treatment_payload = {\n",
    "        \"task\": \"ADD_EDUCATION_AND_EXPERIENCE\",\n",
    "        \"payload\": {\n",
    "            \"education\": cec_treatments[cec_treatment_idx],\n",
    "            \"experience\": cwe_treatments[cwe_treatment_idx]\n",
    "        }\n",
    "    }\n",
    "    type_iii_prompt = base_prompt.replace(\"{Treatment_object}\", str(mixed_treatment_payload))\n",
    "    type_iii_style_guide = shuffled_styles.pop()\n",
    "    type_iii_prompt = type_iii_prompt.replace(\"{style_guide}\", type_iii_style_guide)\n",
    "    treatment_prompts[\"Type_III\"] = {\n",
    "        \"prompt\": type_iii_prompt,\n",
    "        \"style_guide\": type_iii_style_guide,\n",
    "        \"treatment_applied\": {\n",
    "            \"Canadian_Education\": cec_treatments[cec_treatment_idx],\n",
    "            \"Canadian_Work_Experience\": cwe_treatments[cwe_treatment_idx]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    logger.info(f\"Successfully prepared 3 unique treatment prompts for the resume.\")\n",
    "    return treatment_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8a396e",
   "metadata": {},
   "source": [
    "## 5. Main Workflow\n",
    "\n",
    "The following cells walk through the main workflow for generating and saving treated resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import all files from the source collection for the specified sector\n",
    "all_files = get_all_file_ids(\n",
    "    db_name=DB_NAME,\n",
    "    collection_name=SOURCE_COLLECTION_NAME,\n",
    "    mongo_client=MONGO_CLIENT\n",
    ")\n",
    "\n",
    "sector_files = [f for f in all_files if SECTOR in f]\n",
    "if not sector_files:\n",
    "    logger.error(f\"No files found for sector {SECTOR}. Exiting.\")\n",
    "    raise Exception(f\"No files found for sector {SECTOR}.\")\n",
    "logger.info(f\"Found {len(sector_files)} files for sector: {SECTOR}.\")\n",
    "\n",
    "# 2. Initialize the GeminiProcessor\n",
    "treatment_model = GeminiProcessor(\n",
    "    model_name=GEMINI_MODEL_NAME,\n",
    "    temperature=GEMINI_TEMPERATURE,\n",
    "    enable_google_search=ENABLE_GOOGLE_SEARCH\n",
    ")\n",
    "treatment_prompt = treatment_model.load_prompt_template(prompt_file_path=PROMPT_TEMPLATE_PATH)\n",
    "\n",
    "target_collection = MONGO_CLIENT[DB_NAME][TARGET_COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d10bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing loop for a single file (for testing)\n",
    "file = sector_files[0]\n",
    "logger.info(f\"Processing file: {file}\")\n",
    "file_data = get_document_by_fileid(\n",
    "    db_name=DB_NAME,\n",
    "    collection_name=SOURCE_COLLECTION_NAME,\n",
    "    file_id=file,\n",
    "    mongo_client=MONGO_CLIENT\n",
    ")\n",
    "\n",
    "source_resume_data = file_data.get('resume_data', {})\n",
    "if not source_resume_data:\n",
    "    logger.error(f\"No resume data found for file {file}. Skipping.\")\n",
    "    raise Exception(f\"No resume data found for file {file}.\")\n",
    "\n",
    "documents_to_save = []\n",
    "common_metadata = {\n",
    "    'original_file_id': file,\n",
    "    'industry_prefix': file_data.get('industry_prefix'),\n",
    "    'file_size_bytes': file_data.get('file_size_bytes'),\n",
    "    'source_file_hash': file_data.get('file_hash'),\n",
    "}\n",
    "\n",
    "control_resume_target_collection = {\n",
    "        **common_metadata,\n",
    "        \"document_id\": f\"{file}_control\",\n",
    "        \"treatment_type\": \"control\",\n",
    "        \"generation_timestamp\": datetime.datetime.now(),\n",
    "        \"validation\": {\n",
    "            \"focused_similarity_score\": \"\",\n",
    "            \"passed_threshold\": \"N/A\"\n",
    "        },\n",
    "        \"treatment_applied\": \"N/A\",\n",
    "        \"resume_data\": source_resume_data['resume_data'] \n",
    "}\n",
    "documents_to_save.append(control_resume_target_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get two random treatments for Canadian Education and Canadian Work Experience\n",
    "treatment_prompts = select_and_prepare_treatments(\n",
    "    cec_treatment_df,\n",
    "    cwe_treatment_df,\n",
    "    source_resume_data,\n",
    "    treatment_prompt,\n",
    "    STYLE_MODIFIERS\n",
    ")\n",
    "if not treatment_prompts:\n",
    "    logger.error(f\"No treatments available for file {file}. Skipping.\")\n",
    "    raise Exception(f\"No treatments available for file {file}.\")\n",
    "\n",
    "for key, value in treatment_prompts.items():\n",
    "    logger.info(f\"Generating treatment {key} for file {file}.\")\n",
    "    # Generate the treated resume using GeminiProcessor\n",
    "    response = treatment_model.generate_content(\n",
    "        prompt=value['prompt'],\n",
    ")\n",
    "    \n",
    "    if not response or not response.text:\n",
    "        logger.error(f\"Failed to generate content for treatment {key} in file {file}.\")\n",
    "        continue\n",
    "    \n",
    "    # Clean the raw response\n",
    "    treated_resume_data = _clean_raw_llm_response(response.text)\n",
    "    \n",
    "    # Validate the rephrasing with cosine similarity\n",
    "    focused_similarity_score = calculate_focused_similarity(\n",
    "        source_resume_data['resume_data'], treated_resume_data['resume_data']\n",
    "    )\n",
    "    focused_similarity_score = float(focused_similarity_score)\n",
    "    \n",
    "    if focused_similarity_score < 0.85:\n",
    "        logger.warning(f\"Low similarity score ({focused_similarity_score}) for treatment {key} in file {file}. Please add retry logic\")\n",
    "    \n",
    "    final_doc_for_this_version = {\n",
    "            **common_metadata,\n",
    "            \"document_id\": f\"{file.replace('.pdf', '')}_{key}\",\n",
    "            \"treatment_type\": key,\n",
    "            \"generation_timestamp\": datetime.datetime.now(),\n",
    "            \"validation\": {\n",
    "                \"focused_similarity_score\": focused_similarity_score,\n",
    "                \"passed_threshold\": True \n",
    "            },\n",
    "            \"style_guide\": value['style_guide'],\n",
    "            \"treatment_applied\": value['treatment_applied'],\n",
    "            \"resume_data\": treated_resume_data \n",
    "        }\n",
    "    documents_to_save.append(final_doc_for_this_version)\n",
    "    logger.info(f\"  -> Successfully prepared '{key}' for saving.\")\n",
    "\n",
    "if documents_to_save:\n",
    "    target_collection.insert_many(documents_to_save)\n",
    "    logger.info(f\"Successfully saved {len(documents_to_save)} treated resumes for file {file}.\")\n",
    "else:\n",
    "    logger.error(f\"No documents to save for file {file}. Skipping saving step.\")\n",
    "    raise Exception(f\"No documents to save for file {file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rephrased_text(resume_data):\n",
    "    text_parts = []\n",
    "    if 'basics' in resume_data and 'summary' in resume_data['basics']:\n",
    "        text_parts.append(resume_data['basics']['summary'])\n",
    "    if 'work_experience' in resume_data:\n",
    "        for job in resume_data['work_experience']:\n",
    "            if 'highlights' in job and isinstance(job['highlights'], list):\n",
    "                text_parts.append(\" \".join(job['highlights']))\n",
    "    return \" \".join(text_parts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
